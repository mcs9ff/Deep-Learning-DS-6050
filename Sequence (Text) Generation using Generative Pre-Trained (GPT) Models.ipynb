{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad9B4KpIHR3Q"
      },
      "source": [
        "# GPT text generation from scratch with KerasNLP\n",
        "\n",
        "**Author:** [Jesse Chan](https://github.com/jessechancy)<br>\n",
        "**Date created:** 2022/07/25<br>\n",
        "**Last modified:** 2022/07/25<br>\n",
        "**Description:** Using KerasNLP to train a mini-GPT model for text generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRP5IfMeHR3S"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we will use KerasNLP to build a scaled down Generative\n",
        "Pre-Trained (GPT) model. GPT is a Transformer-based model that allows you to generate\n",
        "sophisticated text from a prompt.\n",
        "\n",
        "We will train the model on the [simplebooks-92](https://arxiv.org/abs/1911.12391) corpus,\n",
        "which is a dataset made from several novels. It is a good dataset for this example since\n",
        "it has a small vocabulary and high word frequency, which is beneficial when training a\n",
        "model with few parameters.\n",
        "\n",
        "This example combines concepts from\n",
        "[Text generation with a miniature GPT](https://keras.io/examples/generative/text_generation_with_miniature_gpt/)\n",
        "with KerasNLP abstractions. We will demonstrate how KerasNLP tokenization, layers and\n",
        "metrics simplify the training\n",
        "process, and then show how to generate output text using the KerasNLP sampling utilities.\n",
        "\n",
        "Note: If you are running this example on a Colab,\n",
        "make sure to enable GPU runtime for faster training.\n",
        "\n",
        "This example requires KerasNLP. You can install it via the following command:\n",
        "`pip install keras-nlp`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6QUJuOCHR3S"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras_nlp -q"
      ],
      "metadata": {
        "id": "TKNfLUkZIdk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44cc85bb-ade2-498c-ef99-43176d5b8af7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.5/584.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B6lEs6OUHR3S",
        "outputId": "aee99b5f-627e-43ab-eb8f-58c4a5ec2357",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFnk115YHR3T"
      },
      "source": [
        "## Settings & hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4PUmtywBHR3T"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "BATCH_SIZE = 64\n",
        "SEQ_LEN = 128\n",
        "MIN_TRAINING_SEQ_LEN = 450\n",
        "\n",
        "# Model\n",
        "EMBED_DIM = 256\n",
        "FEED_FORWARD_DIM = 256\n",
        "NUM_HEADS = 3\n",
        "NUM_LAYERS = 2\n",
        "VOCAB_SIZE = 5000  # Limits parameters in model.\n",
        "\n",
        "# Training\n",
        "EPOCHS = 6\n",
        "\n",
        "# Inference\n",
        "NUM_TOKENS_TO_GENERATE = 80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwr6uxOrHR3T"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "Now, let's download the dataset! The SimpleBooks dataset consists of 1,573 Gutenberg books, and has\n",
        "one of the smallest vocabulary size to word-level tokens ratio. It has a vocabulary size of ~98k,\n",
        "a third of WikiText-103's, with around the same number of tokens (~100M). This makes it easy to fit a small model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zAk2uRZaHR3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a731669-159a-4cde-9f4f-556044260968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\n",
            "282386239/282386239 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "keras.utils.get_file(\n",
        "    origin=\"https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "dir = os.path.expanduser(\"~/.keras/datasets/simplebooks/\")\n",
        "\n",
        "# Load simplebooks-92 train set and filter out short lines.\n",
        "raw_train_ds = (\n",
        "    tf.data.TextLineDataset(dir + \"simplebooks-92-raw/train.txt\")\n",
        "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(buffer_size=256)\n",
        ")\n",
        "\n",
        "# Load simplebooks-92 validation set and filter out short lines.\n",
        "raw_val_ds = (\n",
        "    tf.data.TextLineDataset(dir + \"simplebooks-92-raw/valid.txt\")\n",
        "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mGQx4wqHR3U"
      },
      "source": [
        "## Train the tokenizer\n",
        "\n",
        "We train the tokenizer from the training dataset for a vocabulary size of `VOCAB_SIZE`,\n",
        "which is a tuned hyperparameter. We want to limit the vocabulary as much as possible, as\n",
        "we will see later on\n",
        "that it has a large effect on the number of model parameters. We also don't want to include\n",
        "*too few* vocabulary terms, or there would be too many out-of-vocabulary (OOV) sub-words. In\n",
        "addition, three tokens are reserved in the vocabulary:\n",
        "\n",
        "- `\"[PAD]\"` for padding sequences to `SEQ_LEN`. This token has index 0 in both\n",
        "`reserved_tokens` and `vocab`, since `WordPieceTokenizer` (and other layers) consider\n",
        "`0`/`vocab[0]` as the default padding.\n",
        "- `\"[UNK]\"` for OOV sub-words, which should match the default `oov_token=\"[UNK]\"` in\n",
        "`WordPieceTokenizer`.\n",
        "- `\"[BOS]\"` stands for beginning of sentence, but here technically it is a token\n",
        "representing the beginning of each line of training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mYvVIF9zHR3U"
      },
      "outputs": [],
      "source": [
        "# Train tokenizer vocabulary\n",
        "vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "    raw_train_ds,\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    lowercase=True,\n",
        "    reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9KKNtJnHR3U"
      },
      "source": [
        "## Load tokenizer\n",
        "\n",
        "We use the vocabulary data to initialize\n",
        "`keras_nlp.tokenizers.WordPieceTokenizer`. WordPieceTokenizer is an efficient\n",
        "implementation of the WordPiece algorithm used by BERT and other models. It will strip,\n",
        "lower-case and do other irreversible preprocessing operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4FUPvWd4HR3U"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    lowercase=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ8kst6CHR3U"
      },
      "source": [
        "## Tokenize data\n",
        "\n",
        "We preprocess the dataset by tokenizing and splitting it into `features` and `labels`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m8cX4LKUHR3U"
      },
      "outputs": [],
      "source": [
        "# packer adds a start token\n",
        "start_packer = keras_nlp.layers.StartEndPacker(\n",
        "    sequence_length=SEQ_LEN,\n",
        "    start_value=tokenizer.token_to_id(\"[BOS]\"),\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess(inputs):\n",
        "    outputs = tokenizer(inputs)\n",
        "    features = start_packer(outputs)\n",
        "    labels = outputs\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "# Tokenize and split into train and label sequences.\n",
        "train_ds = raw_train_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
        "    tf.data.AUTOTUNE\n",
        ")\n",
        "val_ds = raw_val_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
        "    tf.data.AUTOTUNE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-Un_aLYHR3U"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "We create our scaled down GPT model with the following layers:\n",
        "\n",
        "- One `keras_nlp.layers.TokenAndPositionEmbedding` layer, which combines the embedding\n",
        "for the token and its position.\n",
        "- Multiple `keras_nlp.layers.TransformerDecoder` layers, with the default causal masking.\n",
        "The layer has no cross-attention when run with decoder sequence only.\n",
        "- One final dense linear layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3lSrQdrqHR3U"
      },
      "outputs": [],
      "source": [
        "inputs = keras.layers.Input(shape=(None,), dtype=tf.int32)\n",
        "# Embedding.\n",
        "embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")\n",
        "x = embedding_layer(inputs)\n",
        "# Transformer decoders.\n",
        "for _ in range(NUM_LAYERS):\n",
        "    decoder_layer = keras_nlp.layers.TransformerDecoder(\n",
        "        num_heads=NUM_HEADS,\n",
        "        intermediate_dim=FEED_FORWARD_DIM,\n",
        "    )\n",
        "    x = decoder_layer(x)  # Giving one argument only skips cross-attention.\n",
        "# Output.\n",
        "outputs = keras.layers.Dense(VOCAB_SIZE)(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "perplexity = keras_nlp.metrics.Perplexity(from_logits=True, mask_token_id=0)\n",
        "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[perplexity])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9DGXoPMHR3V"
      },
      "source": [
        "Let's take a look at our model summary - a large majority of the\n",
        "parameters are in the `token_and_position_embedding` and the output `dense` layer!\n",
        "This means that the vocabulary size (`VOCAB_SIZE`) has a large effect on the size of the model,\n",
        "while the number of Transformer decoder layers (`NUM_LAYERS`) doesn't affect it as much."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8QEym7bIHR3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "750df059-d401-4c74-9f9c-8e712a567ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddi  (None, None, 256)         1312768   \n",
            " ng (TokenAndPositionEmbedd                                      \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_decoder (Trans  (None, None, 256)         394749    \n",
            " formerDecoder)                                                  \n",
            "                                                                 \n",
            " transformer_decoder_1 (Tra  (None, None, 256)         394749    \n",
            " nsformerDecoder)                                                \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 5000)        1285000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3387266 (12.92 MB)\n",
            "Trainable params: 3387266 (12.92 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04XS-41wHR3V"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that we have our model, let's train it with the `fit()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HLCbTItEHR3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463503ac-4a84-4a7f-e5e1-3002d3f1b0b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "3169/3169 - 1417s - loss: 4.4935 - perplexity: 89.7921 - val_loss: 4.1366 - val_perplexity: 63.1688 - 1417s/epoch - 447ms/step\n",
            "Epoch 2/6\n",
            "3169/3169 - 1410s - loss: 4.0513 - perplexity: 57.6941 - val_loss: 3.9841 - val_perplexity: 54.2899 - 1410s/epoch - 445ms/step\n",
            "Epoch 3/6\n",
            "3169/3169 - 1396s - loss: 3.9412 - perplexity: 51.6791 - val_loss: 3.9462 - val_perplexity: 52.1174 - 1396s/epoch - 440ms/step\n",
            "Epoch 4/6\n",
            "3169/3169 - 1397s - loss: 3.8806 - perplexity: 48.6370 - val_loss: 3.8985 - val_perplexity: 49.7437 - 1397s/epoch - 441ms/step\n",
            "Epoch 5/6\n",
            "3169/3169 - 1410s - loss: 3.8397 - perplexity: 46.6859 - val_loss: 3.8652 - val_perplexity: 48.1174 - 1410s/epoch - 445ms/step\n",
            "Epoch 6/6\n",
            "3169/3169 - 1396s - loss: 3.8111 - perplexity: 45.3698 - val_loss: 3.8769 - val_perplexity: 48.6609 - 1396s/epoch - 441ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ddf6c50a3e0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.fit(train_ds, validation_data=val_ds, verbose=2, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1BK08QYHR3V"
      },
      "source": [
        "## Inference\n",
        "\n",
        "With our trained model, we can test it out to gauge its performance. To do this\n",
        "we can seed our model with an input sequence starting with the `\"[BOS]\"` token,\n",
        "and progressively sample the model by making predictions for each subsequent\n",
        "token in a loop.\n",
        "\n",
        "To start lets build a prompt with the same shape as our model inputs, containing\n",
        "only the `\"[BOS]\"` token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-Jt8ZG1xHR3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5174100-8ffe-40e7-a7d3-5f41b1e3daa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
              "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# The \"packer\" layers adds the [BOS] token for us.\n",
        "prompt_tokens = start_packer(tokenizer([\"\"]))\n",
        "prompt_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cj6HsK7HR3V"
      },
      "source": [
        "We will use the `keras_nlp.samplers` module for inference, which requires a\n",
        "callback function wrapping the model we just trained. This wrapper calls\n",
        "the model and returns the logit predictions for the current token we are\n",
        "generating.\n",
        "\n",
        "Note: There are two pieces of more advanced functionality available when\n",
        "defining your callback. The first is the ability to take in a `cache` of states\n",
        "computed in previous generation steps, which can be used to speed up generation.\n",
        "The second is the ability to output the final dense \"hidden state\" of each\n",
        "generated token. This is used by `keras_nlp.samplers.ContrastiveSampler`, which\n",
        "avoids repetition by penalizing repeated hidden states. Both are optional, and\n",
        "we will ignore them for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KKzUkmcNHR3V"
      },
      "outputs": [],
      "source": [
        "\n",
        "def next(prompt, cache, index):\n",
        "    logits = model(prompt)[:, index - 1, :]\n",
        "    # Ignore hidden states for now; only needed for contrastive search.\n",
        "    hidden_states = None\n",
        "    return logits, hidden_states, cache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evpnABVTHR3V"
      },
      "source": [
        "Creating the wrapper function is the most complex part of using these functions. Now that\n",
        "it's done, let's test out the different utilities, starting with greedy search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIMqa6eZHR3V"
      },
      "source": [
        "### Greedy search\n",
        "\n",
        "We greedily pick the most probable token at each timestep. In other words, we get the\n",
        "argmax of the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gSW9gns0HR3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4a40f1-9042-4a16-83f7-1c499e72306e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy search generated text: \n",
            "[b'[BOS] \" i am glad to see you , \" said the captain , \" and i have been thinking of it . i have been thinking of it over , and i have been thinking of it . i have heard that you have been in the service , and that you have been in the service of the ship , and that you have been able to do so , and that you have been able to get the ship , and that you have been able to get the ship , and that you have been able to get the ship , and that you have been able to get the ship . \" [PAD] said , \" i will have to do so ,']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_nlp.samplers.GreedySampler()\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,  # Start sampling immediately after the [BOS] token.\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Greedy search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F_FfBcaHR3V"
      },
      "source": [
        "As you can see, greedy search starts out making some sense, but quickly starts repeating\n",
        "itself. This is a common problem with text generation that can be fixed by some of the\n",
        "probabilistic text generation utilities shown later on!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HbVB1tLHR3V"
      },
      "source": [
        "### Beam search\n",
        "\n",
        "At a high-level, beam search keeps track of the `num_beams` most probable sequences at\n",
        "each timestep, and predicts the best next token from all sequences. It is an improvement\n",
        "over greedy search since it stores more possibilities. However, it is less efficient than\n",
        "greedy search since it has to compute and store multiple potential sequences.\n",
        "\n",
        "**Note:** beam search with `num_beams=1` is identical to greedy search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cndGQefAHR3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a5a6f8-db95-42fb-d0a5-1682ce36e5ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam search generated text: \n",
            "[b'[BOS] \" well , i don \\' t think i \\' m glad to see you , \" he said , \" but i \\' m glad i \\' m going to see you , and i \\' ll tell you what i \\' ll do . i \\' ll tell you what i \\' ll do . i \\' ll tell you what i \\' ll do . i \\' ll tell you what i \\' ll do . i \\' ll tell you what i \\' ll do , and i \\' ll tell you what i \\' ll do . i \\' ll tell you what i \\' ll do . i \\' ll tell you what i \\' ll do . i \\' ll']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_nlp.samplers.BeamSampler(num_beams=10)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Beam search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk5-OPYtHR3V"
      },
      "source": [
        "Similar to greedy search, beam search quickly starts repeating itself, since it is still\n",
        "a deterministic method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDhC15W-HR3V"
      },
      "source": [
        "### Random search\n",
        "\n",
        "Random search is our first probabilistic method. At each time step, it samples the next\n",
        "token using the softmax probabilities provided by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c_s22yoDHR3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5037c423-bdb0-4269-a970-9d6d98edad80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random search generated text: \n",
            "[b\"[BOS] ah , you will not want to be in this country mother that paupine . after a widow of fortune and dutch father is a poor woman ; but when you go arman should be married , for i want mrs . time for saving them , and instead of returning when our visit with her husband ' s own business , wives mrs . concy and mabroke is to come back . she ' s called for the slaughter among our mothers if their daughters may be were assured in another case that ever , and she certainly accepted the offer of thanks for sir premarks , since that most\"]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_nlp.samplers.RandomSampler()\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Random search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WxQgSY5HR3V"
      },
      "source": [
        "Voilà, no repetitions! However, with random search, we may see some nonsensical words\n",
        "appearing since any word in the vocabulary has a chance of appearing with this sampling\n",
        "method. This is fixed by our next search utility, top-k search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Po0DOYHR3V"
      },
      "source": [
        "### Top-K search\n",
        "\n",
        "Similar to random search, we sample the next token from the probability distribution\n",
        "provided by the model. The only difference is that here, we select out the top `k` most\n",
        "probable tokens, and distribute the probability mass over them before sampling. This way,\n",
        "we won't be sampling from low probability tokens, and hence we would have less\n",
        "nonsensical words!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Sl1w1NP9HR3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e2ea052-0ea6-47ff-fac4-ffa49a42fe31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-K search generated text: \n",
            "[b'[BOS] in the morning , a few days , there came the news that this was not to be seen from the king , and the swedes he had been so great , and had been captured , for he had been slain by sir gawaine and sir tristram . and that sir tristram had made sir tristram and had been brought up with sir tristram of cornwall , and that the battle of sir tristram was , and that sir tristram had been so sorely wounded that wound round his wound that wound wound sir tristrame and sir tristram had brought him sir tristram and sir tristram to sir tristram . and sir tristram said : [PAD] sir']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_nlp.samplers.TopKSampler(k=10)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-K search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNolU_DsHR3V"
      },
      "source": [
        "### Top-P search\n",
        "\n",
        "Even with the top-k search, there is something to improve upon. With top-k search, the\n",
        "number `k` is fixed, which means it selects the same number of tokens for any probability\n",
        "distribution. Consider two scenarios, one where the probability mass is concentrated over\n",
        "2 words and another where the probability mass is evenly concentrated across 10. Should\n",
        "we choose `k=2` or `k=10`? There is no one size that fits all `k` here.\n",
        "\n",
        "This is where top-p search comes in! Instead of choosing a `k`, we choose a probability\n",
        "`p` that we want the probabilities of the top tokens to sum up to. This way, we can\n",
        "dynamically adjust the `k` based on the probability distribution. By setting `p=0.9`, if\n",
        "90% of the probability mass is concentrated on the top 2 tokens, we can filter out the\n",
        "top 2 tokens to sample from. If instead the 90% is distributed over 10 tokens, it will\n",
        "similarly filter out the top 10 tokens to sample from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7zK9n_DNHR3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d051f8e2-3730-4e4c-fb44-3dc1e55b6642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-P search generated text: \n",
            "[b'[BOS] there was no wonder that this day . at last , the man in the forest , who was not to be near to the foot of the hill , was now very ill . and , if he could see a great white wolf , he would go to his lodge , he would come up to him , and make his way to the other side . so he sat down to the ground , looking for the tree that he had seen the great fire , and there he saw the snake steal out of the cave , and he had no sooner thought that it was very beautiful , and that the snake had made him run off the head . [PAD] then']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_nlp.samplers.TopPSampler(p=0.5)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-P search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5hRjwFjHR3W"
      },
      "source": [
        "### Using callbacks for text generation\n",
        "\n",
        "We can also wrap the utilities in a callback, which allows you to print out a prediction\n",
        "sequence for every epoch of the model! Here is an example of a callback for top-k search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DYqss2zbHR3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a1d3f3-af31-490f-c4ac-7b0a77594792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "Top-K search generated text: \n",
            "[b'[BOS] \" it is not a good thing , sir . he has been sent to me as i said , \" but he did this , and it is my opinion that this will he holds . i am very sure that the men of the french and are in our own language , and that it is no use for it to be taken . if this was not the case , i suppose , i should be killed , to make some resort to this day of the submarines , which i know not , have been very much in the town . i don \\' t want to go into the world , because , as i']\n",
            "\n",
            "1/1 - 13s - loss: 3.9863 - perplexity: 53.9379 - 13s/epoch - 13s/step\n",
            "Epoch 2/2\n",
            "Top-K search generated text: \n",
            "[b'[BOS] \" no , you know , \" he said , \" but the child is not the daughter of the conviction , for i am so much obliged to say , in the present case , to rejoice to appreciate her son . you have had a few hours to get through to - night - - not only the young girl , but the mother is not so much frightened to think about that the young man who will be in his power to be a very good man . it is not only natural that the young girl is the same girl . \" [PAD] , when he was in a man of the']\n",
            "\n",
            "1/1 - 13s - loss: 3.9095 - perplexity: 50.2318 - 13s/epoch - 13s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ddf6c67c6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\n",
        "class TopKTextGenerator(keras.callbacks.Callback):\n",
        "    \"\"\"A callback to generate text from a trained model using top-k.\"\"\"\n",
        "\n",
        "    def __init__(self, k):\n",
        "        self.sampler = keras_nlp.samplers.TopKSampler(k)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        output_tokens = self.sampler(\n",
        "            next=next,\n",
        "            prompt=prompt_tokens,\n",
        "            index=1,\n",
        "        )\n",
        "        txt = tokenizer.detokenize(output_tokens)\n",
        "        print(f\"Top-K search generated text: \\n{txt}\\n\")\n",
        "\n",
        "\n",
        "text_generation_callback = TopKTextGenerator(k=10)\n",
        "# Dummy training loop to demonstrate callback.\n",
        "model.fit(train_ds.take(1), verbose=2, epochs=2, callbacks=[text_generation_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG6XrlpMHR3Z"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "To recap, in this example, we use KerasNLP layers to train a sub-word vocabulary,\n",
        "tokenize training data, create a miniature GPT model, and perform inference with the\n",
        "text generation library.\n",
        "\n",
        "If you would like to understand how Transformers work, or learn more about training the\n",
        "full GPT model, here are some further readings:\n",
        "\n",
        "- Attention Is All You Need [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)\n",
        "- GPT-3 Paper [Brown et al., 2020](https://arxiv.org/abs/2005.14165)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Codeathon 3"
      ],
      "metadata": {
        "id": "W98ptTgRSU7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, you will use the KerasNLP API to build a scaled down Generative Pre-Trained (GPT) model. GPT is a Transformer-based model that allows you to generate sophisticated text and images from a prompt. Using this tutorial guide - GPT text generationLinks to an external site. - as a starting point you will train the model on the simplebooks-92Links to an external site. corpus, which is a dataset made from several novels.\n",
        "\n",
        "Next you will load a pre-trained Large Language Model (LLM) - GPT-2 modelLinks to an external site. (originally invented by OpenAI), finetune it to a specific text style, and generate text based on users' input (also known as prompt). Large language models (LLMs) are a type of machine learning models that are trained on a large corpus of text data to generate outputs for various natural language processing (NLP) tasks, such as text generation, question answering, and machine translation. Generative LLMs are typically based on deep learning neural networks, such as the Transformer architectureLinks to an external site. invented by Google researchers in 2017, and are trained on massive amounts of text data, often involving billions of words. These models, such as Google LaMDALinks to an external site. and PaLMLinks to an external site., are trained with a large dataset from various data sources which allows them to generate output for many tasks. The core of Generative LLMs is predicting the next word in a sentence, often referred as Causal LM Pretraining. In this way LLMs can generate coherent text based on user prompts. For a more pedagogical discussion on language models, you can refer to the Stanford CS324 LLM classLinks to an external site..\n",
        "\n",
        "The KerasNLP API provides a number of pre-trained models, such as Google BertLinks to an external site. and GPT-2Links to an external site.. You can see the list of models available in the KerasNLP repositoryLinks to an external site..\n",
        "\n",
        "You will experiment with at least five (5) pretrained models and fine-tune the models on the Reddit dataset to update its parameters. Generate and evaluate outputs using different pretrained models."
      ],
      "metadata": {
        "id": "gYzeJrN1P012"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the necessary libraries"
      ],
      "metadata": {
        "id": "E_C6ySu2P5E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras_nlp -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ueiZORZngxo",
        "outputId": "af4edffa-9826-4676-fb41-213b01cb63d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/584.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/584.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.5/584.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import math\n",
        "import time\n",
        "import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "GtsChN1kXh9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29baef96-6806-4832-dd19-fdc9e9de627b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Reddit dataset"
      ],
      "metadata": {
        "id": "4kA-e7eHPliB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I was having issues with the larger \"reddit\" dataset, so I went with this one to simplify the process."
      ],
      "metadata": {
        "id": "A8JR_-MgxTEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_data = tfds.load(\"reddit_tifu\", split = \"train\", as_supervised = True)"
      ],
      "metadata": {
        "id": "tdxkzSXHXXal",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "0e5e437cc0914a2ebef54f60c06daa89",
            "88c0de75c2974d918b890c545694f7e8",
            "3ce0faf283584039ba3f9051401da386",
            "9dfc0983699747faaff2affa800f3585",
            "e2a4d8a4851548dfb42fbe0246316734",
            "2ce78924e290446bad38aaf18a94515d",
            "03e4fb0fe68e430caa117bc27ccb0032",
            "4f3a163e00b04ee08ea11becae460ddd",
            "7158518315944daba089eba4b06b9f83",
            "7c54da464ee341169980cfe0c35d56b0",
            "a093bf63756b4dc092296c93944c36c6",
            "83f494f4e7eb414ca4969486b7205d11",
            "eee3609ae7d841d59ff0c519478a74e3",
            "b626a68d185f4f789d91bd5cc7c84f66",
            "db8e81570ccd4310a34b4ed766d93d99",
            "22953579e5564fbaae059873170bd827",
            "4441f22b99164cab90d164ab78216549",
            "9719065b789e465f90806fdd877f7a22",
            "5ff970668d704ceba919ec6619a3d78a",
            "6538e73c2dd64a96b9d88c3ec1f9cf5d",
            "9094dffd774f43bca5963a5da3df08d2",
            "df5ea6270c614e2089d4f80b946f59b0",
            "bcf9510d22c4479f87af5d61860da1be",
            "c6175392dea44fecb9673490c120945e",
            "74df6af21f4b4de5936deff98c5e18fd",
            "4d8d32f220db4f88bc797356321498f2",
            "a9ed5e6d6afb4ba5b88aa6cefcaa9965",
            "eb1c4770a2354700a74e4854c5e2d840",
            "f7d3ec1e36b44b92b6f44a752b49638d",
            "a3fe8c534ff249aa999cb03e9e3815ae",
            "5f4a42afc9fc4184bd352951b0605880",
            "17c796e3b0784e5bb5819b870ea2e64c",
            "f03aa369e5054a169c7d4b691964aae2",
            "26a0acdd645a44eca75c657de468d5cd",
            "5d0bc09565304edd9c738a087890df6b",
            "96972aa659e24ba7bf894a10ed28c8e7",
            "44d99225cc0649bebabadf2806ac4df5",
            "c43da51a4fb14fbf8c71470ada3e1c6e",
            "ccc9470e6cb141e68faae1340811dfab",
            "50ff2a05586344378543ce98959b1f60",
            "8c6ed5b8164e46fcbcb63c49d4af66a2",
            "60e28607b5ac444ca43096047c967444",
            "0ecd81e286f744c790231dd5e38c7d67",
            "f8678fd04c9f49e4975560f7255dabec",
            "95d3288b322c4653b0e7df54250dd2a3",
            "17199cec4d4940aca293f0f33ac03eaa",
            "56fbd200a7b7404b953b19742c1e275f",
            "be862e89159a42b786332f5e06fe882e",
            "47978f9e96454854950bd71925f126a7",
            "9ddd07b470b04c5393c426319a07cde6",
            "4f17a1787bf74a688432575074959b7c",
            "999a6f64b6124ff4b8ffb7ace75fe457",
            "b7e04c965c7647239eee6bb14ad179f8",
            "0e4b3664d765425184bac63ee941e945",
            "87cd9fa5c4f2401dac7a8754c422ada9",
            "f5964b56fa724b748449aead1a56aa28",
            "cb7c8f0a5fa04aeab6012dad1a818429",
            "84f8004066f148efa51f140d3adcb08c",
            "c762b12032dc45158ab76aa47306ecb7",
            "e174c5dc165a4dbba7953401bc63f80c",
            "1e67bea36ee64a568a4889e360372bd5",
            "234562ca3d494b25b5bc43bd57102cf3",
            "ae5f83fe8a484790aeb60db99253f6cb",
            "d9a6b5709b434c128ed2769b21bbc055",
            "a6f9b23c25a64d52bda928552e427a71",
            "88789e5d53d749429396ea50e3e390cf"
          ]
        },
        "outputId": "32377288-819a-4a85-9b03-eaaf15b17ad8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 639.54 MiB (download: 639.54 MiB, generated: 141.46 MiB, total: 781.00 MiB) to /root/tensorflow_datasets/reddit_tifu/short/1.1.2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e5e437cc0914a2ebef54f60c06daa89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83f494f4e7eb414ca4969486b7205d11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcf9510d22c4479f87af5d61860da1be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26a0acdd645a44eca75c657de468d5cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...:   0%|          | 0/79740 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95d3288b322c4653b0e7df54250dd2a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/reddit_tifu/short/1.1.2.incompleteL8XTV7/reddit_tifu-train.tfrecord*...:  …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5964b56fa724b748449aead1a56aa28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset reddit_tifu downloaded and prepared to /root/tensorflow_datasets/reddit_tifu/short/1.1.2. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the data"
      ],
      "metadata": {
        "id": "Km5D-fwuNAyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_reddit = (reddit_data.map(lambda document, _: document).batch(32).cache().prefetch(tf.data.AUTOTUNE))"
      ],
      "metadata": {
        "id": "7ejEUez4qsuz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune the Parameters"
      ],
      "metadata": {
        "id": "snlHoO-fUJdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters for the first GPT model:"
      ],
      "metadata": {
        "id": "BIfx-S0ku88z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for 1st model attempt\n",
        "\n",
        "# number of epochs\n",
        "epochs = 1\n",
        "\n",
        "# Reduce the size of the dataset\n",
        "train_reddit = train_reddit.take(500)\n",
        "\n",
        "# Learning rate schedule\n",
        "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(5e-5, decay_steps=tf.data.experimental.cardinality(train_reddit).numpy() * epochs, end_learning_rate=0.0,)\n",
        "\n",
        "# Loss\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
      ],
      "metadata": {
        "id": "RMKqkoQVSX0-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to generate text"
      ],
      "metadata": {
        "id": "B9F1Fe4XUsmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://keras.io/examples/generative/gpt2_text_generation_with_kerasnlp/\n",
        "\n",
        "def generate_text(model, input_text, max_length = 500):\n",
        "    start = time.time()\n",
        "\n",
        "    output = model.generate(input_text, max_length = max_length)\n",
        "    print(\"\\nGPT-2 Output:\")\n",
        "    print(output)\n",
        "\n",
        "    end = time.time()\n",
        "    print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "id": "7TS8PVfmUsxb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-2 Models"
      ],
      "metadata": {
        "id": "C2eocR7yWaJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1st attempt at the GPT-2 Model:"
      ],
      "metadata": {
        "id": "Rbt818zIxpZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the model name\n",
        "model_name = \"gpt2_base_en\"\n",
        "\n",
        "# initialize the preprocessor and the model\n",
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    model_name,\n",
        "    sequence_length = 128,\n",
        ")\n",
        "tmp_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    model_name, preprocessor=preprocessor\n",
        ")\n",
        "\n",
        "# compile the model\n",
        "tmp_lm.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss = loss,\n",
        "    weighted_metrics = [\"accuracy\"],\n",
        ")\n",
        "\n",
        "# train the model\n",
        "tmp_lm.fit(train_reddit, epochs = epochs)\n",
        "\n",
        "# generate text\n",
        "generate_text(tmp_lm, \"How do I create a GPT model?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xpLqmNWsZH_",
        "outputId": "715e9c2a-ee74-4bbd-80a8-e478b7ae6a1e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/vocab.json\n",
            "1042301/1042301 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/merges.txt\n",
            "456318/456318 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/model.h5\n",
            "497986112/497986112 [==============================] - 3s 0us/step\n",
            "500/500 [==============================] - 5141s 10s/step - loss: 3.3046 - accuracy: 0.3264\n",
            "\n",
            "GPT-2 Output:\n",
            "How do I create a GPT model?\n",
            "\n",
            "a lot of people have tried to do this, but it just takes too much time. i have a few ideas, and i'm not sure why anyone would try to do it this way, but i've never had the time.\n",
            "\n",
            "edit: i was going on vacation, so i decided to try to make this work for me. i started by creating the GPT model, and then i created a couple of different images, one for the \"gpts\" part and the next for the \"gts.\" so now i have the \"gts\" and \"gts-gts\"\n",
            "TOTAL TIME ELAPSED: 42.35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my next model, I will increase the number of epochs as well as enlarge the size of the datset that the model is trained on."
      ],
      "metadata": {
        "id": "POKdAesguHaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters:"
      ],
      "metadata": {
        "id": "DJ_iGo1uZYlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for 2nd model attempt\n",
        "\n",
        "# increase the number of epochs\n",
        "epochs = 5\n",
        "\n",
        "# enlarge the size of the dataset\n",
        "train_reddit = train_reddit.take(1000)\n",
        "\n",
        "# Learning rate schedule\n",
        "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(5e-5, decay_steps=tf.data.experimental.cardinality(train_reddit).numpy() * epochs, end_learning_rate=0.0,)\n",
        "\n",
        "# Loss\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
      ],
      "metadata": {
        "id": "9HAxNI8WWn0q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the model name\n",
        "model_name = \"gpt2_base_en\"\n",
        "\n",
        "# initialize the preprocessor and the model\n",
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    model_name,\n",
        "    sequence_length = 128,\n",
        ")\n",
        "tmp_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    model_name, preprocessor=preprocessor\n",
        ")\n",
        "\n",
        "# compile the model\n",
        "tmp_lm.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss = loss,\n",
        "    weighted_metrics = [\"accuracy\"],\n",
        ")\n",
        "\n",
        "# train the model\n",
        "tmp_lm.fit(train_reddit, epochs = epochs)\n",
        "\n",
        "# generate text\n",
        "generate_text(tmp_lm, \"How do I create a GPT model?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRjBe_9XNKg5",
        "outputId": "c6d21909-aba0-4546-edfd-33fdabb42cd3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "500/500 [==============================] - 5100s 10s/step - loss: 3.2939 - accuracy: 0.3275\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 5088s 10s/step - loss: 3.1421 - accuracy: 0.3457\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 5088s 10s/step - loss: 3.0591 - accuracy: 0.3577\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 5066s 10s/step - loss: 3.0126 - accuracy: 0.3634\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 5074s 10s/step - loss: 2.9853 - accuracy: 0.3669\n",
            "\n",
            "GPT-2 Output:\n",
            "How do I create a GPT model?\n",
            "\n",
            "my first project was to create a gps database for my school. i wanted to create a table of all classes in an english department and use it to create the model for my school.\n",
            "\n",
            "after a week of work i decided to create a model that was going to look like this:\n",
            "\n",
            "public class model { public static string get_class() { return \"class\"; } public static int get_class_id(int id)(int id) { return id; } } public string get_model(int model, int id) { return id\n",
            "TOTAL TIME ELAPSED: 41.00s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my last GPT model, I want to experiment with a new loss function that includes label smoothing."
      ],
      "metadata": {
        "id": "NAX5X4kANF_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters:"
      ],
      "metadata": {
        "id": "D6870a6bZS2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for 2nd model attempt\n",
        "\n",
        "# increase the number of epochs\n",
        "epochs = 1\n",
        "\n",
        "# enlarge the size of the dataset\n",
        "train_reddit = train_reddit.take(1000)\n",
        "\n",
        "# Learning rate schedule\n",
        "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(5e-5, decay_steps=tf.data.experimental.cardinality(train_reddit).numpy() * epochs, end_learning_rate=0.0,)\n",
        "\n",
        "# Loss\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "\n",
        "# Loss Function with Label Smoothing\n",
        "class CustomSparseCategoricalCrossentropy(tf.keras.losses.Loss):\n",
        "    def __init__(self, smoothing=0.1, from_logits=True):\n",
        "        super(CustomSparseCategoricalCrossentropy, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.from_logits = from_logits\n",
        "        self.cce = tf.keras.losses.CategoricalCrossentropy(\n",
        "            from_logits=from_logits, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[2])\n",
        "        y_true = y_true * (1 - self.smoothing) + (self.smoothing / tf.cast(tf.shape(y_true)[2], tf.float32))\n",
        "        return tf.reduce_mean(self.cce(y_true, y_pred))"
      ],
      "metadata": {
        "id": "URdTjHe8NGOy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the model name\n",
        "model_name = \"gpt2_base_en\"\n",
        "\n",
        "# initialize the preprocessor and the model\n",
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    model_name,\n",
        "    sequence_length = 128,\n",
        ")\n",
        "tmp_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    model_name, preprocessor=preprocessor\n",
        ")\n",
        "\n",
        "# compile the model with updated loss function\n",
        "tmp_lm.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss = CustomSparseCategoricalCrossentropy(smoothing=0.1),\n",
        "    weighted_metrics = [\"accuracy\"],\n",
        ")\n",
        "\n",
        "# train the model\n",
        "tmp_lm.fit(train_reddit, epochs = epochs)\n",
        "\n",
        "# generate text\n",
        "generate_text(tmp_lm, \"How do I create a GPT model?\")"
      ],
      "metadata": {
        "id": "EYRiKHLgWqhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029ba104-5248-4996-a742-1b9c453191ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/vocab.json\n",
            "1042301/1042301 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/merges.txt\n",
            "456318/456318 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/model.h5\n",
            "497986112/497986112 [==============================] - 3s 0us/step\n",
            "500/500 [==============================] - 4410s 9s/step - loss: 4.2801 - accuracy: 0.3252\n",
            "\n",
            "GPT-2 Output:\n",
            "How do I create a GPT model?\n",
            "\n",
            "i'm a highschool senior. i was in a school for a high school student, and he was the only one in my class that wasn't a gt. he wanted me to have a model of his penis. so when we were talking, he told us that he was a student of the school, and that he wanted me to make him an \"uniformed\" model of him.\n",
            "\n",
            "i was like \"i'll give that to you guys\". so i went to the gym and made a uniform of the model of his penis, with his name.\n",
            "\n",
            "i was in my room and i noticed that my penis was\n",
            "TOTAL TIME ELAPSED: 36.37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OPT Models:"
      ],
      "metadata": {
        "id": "1BRs7mCUQnI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my first OPT model, I will begin with the same parameters as the original GPT model."
      ],
      "metadata": {
        "id": "tVwuPmOkVEsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters for the 1st OPT Model:"
      ],
      "metadata": {
        "id": "xIR7K6vMu26b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for 1st model attempt\n",
        "\n",
        "# number of epochs\n",
        "epochs = 1\n",
        "\n",
        "# Reduce the size of the dataset\n",
        "train_reddit = train_reddit.take(500)\n",
        "\n",
        "# Learning rate schedule\n",
        "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(5e-5, decay_steps=tf.data.experimental.cardinality(train_reddit).numpy() * epochs, end_learning_rate=0.0,)\n",
        "\n",
        "# Loss\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
      ],
      "metadata": {
        "id": "k-JmUpvtu2FP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1st attempt at the OPT model:"
      ],
      "metadata": {
        "id": "IOueEYQQyA_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the model name\n",
        "model_name = \"opt_125m_en\"\n",
        "\n",
        "# initialize the preprocessor and the model\n",
        "preprocessor = keras_nlp.models.OPTCausalLMPreprocessor.from_preset(\n",
        "    model_name,\n",
        "    sequence_length = 128,\n",
        ")\n",
        "tmp_lm = keras_nlp.models.OPTCausalLM.from_preset(\n",
        "    model_name, preprocessor=preprocessor\n",
        ")\n",
        "\n",
        "# compile the model\n",
        "tmp_lm.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=loss,\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# train the model\n",
        "tmp_lm.fit(train_reddit, epochs = epochs)\n",
        "\n",
        "# generate text\n",
        "generate_text(tmp_lm, \"How do I create a GPT model?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcwelX0tQp6w",
        "outputId": "d713a69c-c7ae-453e-a961-3a5aaed994f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/opt_125m_en/v1/vocab.json\n",
            "898822/898822 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/opt_125m_en/v1/merges.txt\n",
            "456318/456318 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/opt_125m_en/v1/model.h5\n",
            "501175368/501175368 [==============================] - 3s 0us/step\n",
            "500/500 [==============================] - 4414s 9s/step - loss: 3.1034 - accuracy: 0.3515\n",
            "\n",
            "GPT-2 Output:\n",
            "How do I create a GPT model?\n",
            "\n",
            "a few days ago i had to make a model of a galaxy s6 and i had a few things to do, so i decided to use the gpt tool to create a gpt file for it. i created the model and then copied it to a usb drive, but i didn't have any other tools to do so and it was still not working. i was so confused, and then my phone died, i had to use the gpt tool, and i had to use a computer to get it back to work. i had to go to the repair store and\n",
            "TOTAL TIME ELAPSED: 32.58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my 2nd OPT model, I will enlarge the size of the datset that the model is trained on. I wanted to increase the number of epochs, but this proved too costly in terms of computing power."
      ],
      "metadata": {
        "id": "eOIlCGmuuJSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters:"
      ],
      "metadata": {
        "id": "I8nDNQfkZOof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for 2nd model attempt\n",
        "\n",
        "# increase the number of epochs\n",
        "epochs = 1\n",
        "\n",
        "# enlarge the size of the dataset\n",
        "train_reddit = train_reddit.take(1000)\n",
        "\n",
        "# Learning rate schedule\n",
        "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(5e-5, decay_steps=tf.data.experimental.cardinality(train_reddit).numpy() * epochs, end_learning_rate=0.0,)\n",
        "\n",
        "# Loss\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
      ],
      "metadata": {
        "id": "3rJCbtDNUwVg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the model name\n",
        "model_name = \"opt_125m_en\"\n",
        "\n",
        "# initialize the preprocessor and the model\n",
        "preprocessor = keras_nlp.models.OPTCausalLMPreprocessor.from_preset(\n",
        "    model_name,\n",
        "    sequence_length = 128,\n",
        ")\n",
        "tmp_lm = keras_nlp.models.OPTCausalLM.from_preset(\n",
        "    model_name, preprocessor=preprocessor\n",
        ")\n",
        "\n",
        "# compile the model\n",
        "tmp_lm.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=loss,\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# train the model\n",
        "tmp_lm.fit(train_reddit, epochs = epochs)\n",
        "\n",
        "# generate text\n",
        "generate_text(tmp_lm, \"How do I create a GPT model?\")"
      ],
      "metadata": {
        "id": "WBHEwsfgYbrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ac2be1-e42a-407f-8a49-492fb38ef15c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 4503s 9s/step - loss: 3.1030 - accuracy: 0.3517\n",
            "\n",
            "GPT-2 Output:\n",
            "How do I create a GPT model?\n",
            "\n",
            "i created my own gpt model with my own code and created it using the gpt command-line, then i used the command-line again, and i created the model using the command-line again, but it was still the same code. i created the gpt model with all the files that i wanted to create, and i created a folder with files for each folder i want.\n",
            "\n",
            "i also created a folder with all of the files i wanted to create, and a folder with all of the files that i want to create. \n",
            "\n",
            "i then\n",
            "TOTAL TIME ELAPSED: 34.67s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: I was unable to fully train the models with a higher number of epochs due to computing limitations. I can run them and resubmit later when Colab has improved accessibility."
      ],
      "metadata": {
        "id": "q1jHpjrUUw6W"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e5e437cc0914a2ebef54f60c06daa89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88c0de75c2974d918b890c545694f7e8",
              "IPY_MODEL_3ce0faf283584039ba3f9051401da386",
              "IPY_MODEL_9dfc0983699747faaff2affa800f3585"
            ],
            "layout": "IPY_MODEL_e2a4d8a4851548dfb42fbe0246316734"
          }
        },
        "88c0de75c2974d918b890c545694f7e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce78924e290446bad38aaf18a94515d",
            "placeholder": "​",
            "style": "IPY_MODEL_03e4fb0fe68e430caa117bc27ccb0032",
            "value": "Dl Completed...: 100%"
          }
        },
        "3ce0faf283584039ba3f9051401da386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f3a163e00b04ee08ea11becae460ddd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7158518315944daba089eba4b06b9f83",
            "value": 1
          }
        },
        "9dfc0983699747faaff2affa800f3585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c54da464ee341169980cfe0c35d56b0",
            "placeholder": "​",
            "style": "IPY_MODEL_a093bf63756b4dc092296c93944c36c6",
            "value": " 1/1 [00:10&lt;00:00, 10.15s/ url]"
          }
        },
        "e2a4d8a4851548dfb42fbe0246316734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce78924e290446bad38aaf18a94515d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e4fb0fe68e430caa117bc27ccb0032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f3a163e00b04ee08ea11becae460ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7158518315944daba089eba4b06b9f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c54da464ee341169980cfe0c35d56b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a093bf63756b4dc092296c93944c36c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83f494f4e7eb414ca4969486b7205d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eee3609ae7d841d59ff0c519478a74e3",
              "IPY_MODEL_b626a68d185f4f789d91bd5cc7c84f66",
              "IPY_MODEL_db8e81570ccd4310a34b4ed766d93d99"
            ],
            "layout": "IPY_MODEL_22953579e5564fbaae059873170bd827"
          }
        },
        "eee3609ae7d841d59ff0c519478a74e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4441f22b99164cab90d164ab78216549",
            "placeholder": "​",
            "style": "IPY_MODEL_9719065b789e465f90806fdd877f7a22",
            "value": "Dl Size...: 100%"
          }
        },
        "b626a68d185f4f789d91bd5cc7c84f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff970668d704ceba919ec6619a3d78a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6538e73c2dd64a96b9d88c3ec1f9cf5d",
            "value": 1
          }
        },
        "db8e81570ccd4310a34b4ed766d93d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9094dffd774f43bca5963a5da3df08d2",
            "placeholder": "​",
            "style": "IPY_MODEL_df5ea6270c614e2089d4f80b946f59b0",
            "value": " 639/639 [00:10&lt;00:00, 61.38 MiB/s]"
          }
        },
        "22953579e5564fbaae059873170bd827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4441f22b99164cab90d164ab78216549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9719065b789e465f90806fdd877f7a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ff970668d704ceba919ec6619a3d78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6538e73c2dd64a96b9d88c3ec1f9cf5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9094dffd774f43bca5963a5da3df08d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df5ea6270c614e2089d4f80b946f59b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcf9510d22c4479f87af5d61860da1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6175392dea44fecb9673490c120945e",
              "IPY_MODEL_74df6af21f4b4de5936deff98c5e18fd",
              "IPY_MODEL_4d8d32f220db4f88bc797356321498f2"
            ],
            "layout": "IPY_MODEL_a9ed5e6d6afb4ba5b88aa6cefcaa9965"
          }
        },
        "c6175392dea44fecb9673490c120945e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb1c4770a2354700a74e4854c5e2d840",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d3ec1e36b44b92b6f44a752b49638d",
            "value": "Extraction completed...: "
          }
        },
        "74df6af21f4b4de5936deff98c5e18fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3fe8c534ff249aa999cb03e9e3815ae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f4a42afc9fc4184bd352951b0605880",
            "value": 0
          }
        },
        "4d8d32f220db4f88bc797356321498f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c796e3b0784e5bb5819b870ea2e64c",
            "placeholder": "​",
            "style": "IPY_MODEL_f03aa369e5054a169c7d4b691964aae2",
            "value": " 0/0 [00:10&lt;?, ? file/s]"
          }
        },
        "a9ed5e6d6afb4ba5b88aa6cefcaa9965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb1c4770a2354700a74e4854c5e2d840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d3ec1e36b44b92b6f44a752b49638d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3fe8c534ff249aa999cb03e9e3815ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5f4a42afc9fc4184bd352951b0605880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17c796e3b0784e5bb5819b870ea2e64c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03aa369e5054a169c7d4b691964aae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26a0acdd645a44eca75c657de468d5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d0bc09565304edd9c738a087890df6b",
              "IPY_MODEL_96972aa659e24ba7bf894a10ed28c8e7",
              "IPY_MODEL_44d99225cc0649bebabadf2806ac4df5"
            ],
            "layout": "IPY_MODEL_c43da51a4fb14fbf8c71470ada3e1c6e"
          }
        },
        "5d0bc09565304edd9c738a087890df6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc9470e6cb141e68faae1340811dfab",
            "placeholder": "​",
            "style": "IPY_MODEL_50ff2a05586344378543ce98959b1f60",
            "value": "Generating splits...: 100%"
          }
        },
        "96972aa659e24ba7bf894a10ed28c8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c6ed5b8164e46fcbcb63c49d4af66a2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60e28607b5ac444ca43096047c967444",
            "value": 1
          }
        },
        "44d99225cc0649bebabadf2806ac4df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ecd81e286f744c790231dd5e38c7d67",
            "placeholder": "​",
            "style": "IPY_MODEL_f8678fd04c9f49e4975560f7255dabec",
            "value": " 1/1 [00:26&lt;00:00, 26.01s/ splits]"
          }
        },
        "c43da51a4fb14fbf8c71470ada3e1c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ccc9470e6cb141e68faae1340811dfab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50ff2a05586344378543ce98959b1f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c6ed5b8164e46fcbcb63c49d4af66a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e28607b5ac444ca43096047c967444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ecd81e286f744c790231dd5e38c7d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8678fd04c9f49e4975560f7255dabec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d3288b322c4653b0e7df54250dd2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17199cec4d4940aca293f0f33ac03eaa",
              "IPY_MODEL_56fbd200a7b7404b953b19742c1e275f",
              "IPY_MODEL_be862e89159a42b786332f5e06fe882e"
            ],
            "layout": "IPY_MODEL_47978f9e96454854950bd71925f126a7"
          }
        },
        "17199cec4d4940aca293f0f33ac03eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ddd07b470b04c5393c426319a07cde6",
            "placeholder": "​",
            "style": "IPY_MODEL_4f17a1787bf74a688432575074959b7c",
            "value": "Generating train examples...:  97%"
          }
        },
        "56fbd200a7b7404b953b19742c1e275f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_999a6f64b6124ff4b8ffb7ace75fe457",
            "max": 79740,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7e04c965c7647239eee6bb14ad179f8",
            "value": 79740
          }
        },
        "be862e89159a42b786332f5e06fe882e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e4b3664d765425184bac63ee941e945",
            "placeholder": "​",
            "style": "IPY_MODEL_87cd9fa5c4f2401dac7a8754c422ada9",
            "value": " 77361/79740 [00:24&lt;00:00, 2885.01 examples/s]"
          }
        },
        "47978f9e96454854950bd71925f126a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "9ddd07b470b04c5393c426319a07cde6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f17a1787bf74a688432575074959b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "999a6f64b6124ff4b8ffb7ace75fe457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e04c965c7647239eee6bb14ad179f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e4b3664d765425184bac63ee941e945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cd9fa5c4f2401dac7a8754c422ada9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5964b56fa724b748449aead1a56aa28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb7c8f0a5fa04aeab6012dad1a818429",
              "IPY_MODEL_84f8004066f148efa51f140d3adcb08c",
              "IPY_MODEL_c762b12032dc45158ab76aa47306ecb7"
            ],
            "layout": "IPY_MODEL_e174c5dc165a4dbba7953401bc63f80c"
          }
        },
        "cb7c8f0a5fa04aeab6012dad1a818429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e67bea36ee64a568a4889e360372bd5",
            "placeholder": "​",
            "style": "IPY_MODEL_234562ca3d494b25b5bc43bd57102cf3",
            "value": "Shuffling /root/tensorflow_datasets/reddit_tifu/short/1.1.2.incompleteL8XTV7/reddit_tifu-train.tfrecord*...:  72%"
          }
        },
        "84f8004066f148efa51f140d3adcb08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae5f83fe8a484790aeb60db99253f6cb",
            "max": 79740,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9a6b5709b434c128ed2769b21bbc055",
            "value": 79740
          }
        },
        "c762b12032dc45158ab76aa47306ecb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f9b23c25a64d52bda928552e427a71",
            "placeholder": "​",
            "style": "IPY_MODEL_88789e5d53d749429396ea50e3e390cf",
            "value": " 57711/79740 [00:00&lt;00:00, 209617.38 examples/s]"
          }
        },
        "e174c5dc165a4dbba7953401bc63f80c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1e67bea36ee64a568a4889e360372bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234562ca3d494b25b5bc43bd57102cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae5f83fe8a484790aeb60db99253f6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a6b5709b434c128ed2769b21bbc055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6f9b23c25a64d52bda928552e427a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88789e5d53d749429396ea50e3e390cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
